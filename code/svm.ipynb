{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data ...\n",
      "Loading previous data ...\n",
      "(11120, 8) (11120,)\n",
      "(7784, 8) (7784,)\n",
      "(3336, 8) (3336,)\n",
      "Fitting SVM ...\n",
      "Evaluating ...\n",
      "Accuracy is 0.903177.\n",
      "[[1544  119]\n",
      " [ 204 1469]]\n",
      "Precision score is 0.925063.\n",
      "Recall score is 0.878063.\n",
      "F1 score is 0.900951.\n",
      "-----------------------------------\n",
      "Fitting SVM ...\n",
      "Evaluating ...\n",
      "Accuracy is 0.897182.\n",
      "[[1477  186]\n",
      " [ 157 1516]]\n",
      "Precision score is 0.890717.\n",
      "Recall score is 0.906157.\n",
      "F1 score is 0.898370.\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "import read\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "TUNING = False  # Set this to False if you don't want to tune\n",
    "\n",
    "print (\"Reading data ...\")\n",
    "x_all, y_all = read.read(LOAD_DATA=False)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_all, y_all, test_size=0.3, random_state=42)\n",
    "print (x_train.shape, y_train.shape)\n",
    "print (x_test.shape, y_test.shape)\n",
    "\n",
    "if TUNING:\n",
    "\n",
    "    tuned_parameters = [{'gamma': [1e-3, 1e-2, 1/8],\n",
    "                         'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "    scores = [\"accuracy\", \"f1\"]\n",
    "\n",
    "    for score in scores:\n",
    "        print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "        print(\"\")\n",
    "\n",
    "        clf = GridSearchCV(SVC(kernel=\"rbf\"), tuned_parameters, cv=5, scoring=score, n_jobs=2)\n",
    "        clf.fit(x_train, y_train)\n",
    "\n",
    "        print(\"Best parameters set found on development set:\")\n",
    "        print(\"\")\n",
    "        print(clf.best_estimator_)\n",
    "        print (clf.best_params_)\n",
    "        print(\"\")\n",
    "        print(\"Grid scores on development set:\")\n",
    "        print(\"\")\n",
    "        print (clf.best_score_)\n",
    "        print(\"\")\n",
    "\n",
    "        print(\"Detailed classification report:\")\n",
    "        print(\"\")\n",
    "        print(\"The model is trained on the full development set.\")\n",
    "        print(\"The scores are computed on the full evaluation set.\")\n",
    "        print(\"\")\n",
    "        y_true, y_pred = y_test, clf.predict(x_test)\n",
    "        print(classification_report(y_true, y_pred))\n",
    "        print(\"\")\n",
    "\n",
    "else:\n",
    "    models = [SVC(),\n",
    "              SVC(C=1000, cache_size=200, class_weight=None, coef0=0.0,\n",
    "                  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',\n",
    "                  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "                  tol=0.001, verbose=False)\n",
    "              ]\n",
    "    for model in models:\n",
    "        print (\"Fitting SVM ...\")\n",
    "        model.fit(x_train, y_train)\n",
    "\n",
    "        print (\"Evaluating ...\")\n",
    "        y_pred = model.predict(x_test)\n",
    "\n",
    "        print (\"Accuracy is %f.\" % accuracy_score(y_test, y_pred))\n",
    "        print (confusion_matrix(y_test, y_pred))\n",
    "        print (\"Precision score is %f.\" % precision_score(y_test, y_pred))\n",
    "        print (\"Recall score is %f.\" % recall_score(y_test, y_pred))\n",
    "        print (\"F1 score is %f.\" % f1_score(y_test, y_pred))\n",
    "        print (\"-----------------------------------\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
